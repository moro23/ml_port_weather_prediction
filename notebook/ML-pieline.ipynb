{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azureml-mlflow azureml-sdk scikit-learn skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## core python libraries\n",
    "from math import sqrt\n",
    "import pickle\n",
    "\n",
    "## libraries for data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## libraries for data visualization\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "## librarires for project trancking \n",
    "import mlflow\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace , Dataset\n",
    "from azureml.core.model import Model \n",
    "from azureml.core.authentication import ServicePrincipalAuthentication \n",
    "from azureml.train.automl import AutoMLImageConfig \n",
    "\n",
    "## libraries for splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## libraries for scaling the features \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## libraries for training ml models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## libraries for hyparameter tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## libraries for computing metrics score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "## libraries for model packaging\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "## muting errors\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets get placeholder variables \n",
    "subscription_id = '5d6d4b4a-f629-47f1-a748-1d80f9a6031a'\n",
    "resource_group = 'Learn_MLOps'\n",
    "workspace_name = 'MLOps_WS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting up a workspace\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets get a tracking ID for where MLflow exp and artifacts would be logged\n",
    "uri = workspace.get_mlflow_tracking_uri( )\n",
    "## lets connect to the tracking ID\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing pre-processed dataset\n",
    "dataset = Dataset.get_by_name(workspace, name='weather_ds_portofTurku')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets convert the dataset into pandas dataframe\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up A Validation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_valid = train_test_split(df_train_full, test_size=0.25, random_state=11)\n",
    "\n",
    "\n",
    "print(f'Size Of Full Training Dataset: {len(df_train_full)}')\n",
    "print(f'Size Of Training Dataset: {len(df_train)}')\n",
    "print(f'Size Of Validation Dataset: {len(df_valid)}')\n",
    "print(f'Size Of Testing Dataset: {len(df_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_valid = train_test_split(df_train_full, test_size=0.25, random_state=11)\n",
    "\n",
    "\n",
    "print(f'Size Of Full Training Dataset: {len(df_train_full)}')\n",
    "print(f'Size Of Training Dataset: {len(df_train)}')\n",
    "print(f'Size Of Validation Dataset: {len(df_valid)}')\n",
    "print(f'Size Of Testing Dataset: {len(df_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving The Results of Splitting Dataset \n",
    "\n",
    "df_train_full.to_csv('../dataset/full_training_data.csv', index=False)\n",
    "df_train.to_csv('../dataset/trianing_data.csv', index=False)\n",
    "df_valid.to_csv('../dataset/validation_data.csv', index=False)\n",
    "df_test.to_csv('../dataset/testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get the datastore to upload the prepared data\n",
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets upload the local file from src_dir to the target_path in the datastore\n",
    "datastore.upload(src_dir='../dataset/', target_path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets select our target variables \n",
    "y_train_full = df_train_full['Future_weather_condition'].values\n",
    "y_train = df_train['Future_weather_condition'].values\n",
    "y_valid = df_valid['Future_weather_condition'].values\n",
    "y_test = df_test['Future_weather_condition'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets delete the target column from the dataframe\n",
    "del  df_train_full['Future_weather_condition']\n",
    "del  df_train['Future_weather_condition']\n",
    "del  df_valid['Future_weather_condition']\n",
    "del  df_test['Future_weather_condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets some of the feature columns\n",
    "columns = ['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', \n",
    "           'Visibility_km','Pressure_millibars', 'Current_weather_condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting pandas dataframe to numpy array \n",
    "X_train_full = df_train_full[columns].values\n",
    "X_train = df_train[columns].values\n",
    "X_test = df_test[columns].values\n",
    "X_valid = df_valid[columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling And Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create an instance of standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_full = sc.fit_transform(X_train_full) \n",
    "X_train = sc.transform(X_train)\n",
    "X_valid = sc.transform(X_valid)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training And Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets initiate the training or experiment\n",
    "myexperiment = Experiment(workspace, \"support-vector-machine\")\n",
    "\n",
    "##  lets initiate the mlflow experiment\n",
    "mlflow.set_experiment(\"mlflow-support-vector-machine\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets perform a hyperparameter search to find the best parameters\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C': [1, 10]}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "## lets initialize a run in Azureml and mlflow experiments\n",
    "run = myexperiment.start_logging()\n",
    "\n",
    "#mlflow.start_run()\n",
    "\n",
    "run.log('dataset name', dataset.name)\n",
    "run.log('dataset version', dataset.version)\n",
    "svc_grid = GridSearchCV(svc, parameters)\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=svc_grid.get_params(deep=True)\n",
    "          ['estimator__C'], kernel=svc_grid.get_params(deep=True)\n",
    "           ['estimator__kernel'])\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "## lets log the training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"C\", svc_grid.get_params(deep=True)['estimator__C'])\n",
    "run.log(\"Kernel\", svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lesklearninitiate the training or experiment\n",
    "myexperiment = Experiment(workspace, \"random-forest-classifier\")\n",
    "\n",
    "##  lets initiate the mlflow experiment\n",
    "mlflow.set_experiment(\"mlflow-random-forest-classifier\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## lets create an instance of a random forest classifier\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets initialize runs in Azureml and mlflow\n",
    "run = myexperiment.start_logging()\n",
    "\n",
    "#mlflow.start_run()\n",
    "\n",
    "## lets log the dataset used\n",
    "run.log('dataset name', dataset.name)\n",
    "run.log('dataset Version', dataset.version)\n",
    "\n",
    "## lets fit the data to the random forest alg\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "## Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log('max_depth', 10)\n",
    "run.log('random_state', 0)\n",
    "run.log('n_estimators', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation And Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets generates the predictions for svm classifier\n",
    "y_valid_pred = svc.predict(X_valid)\n",
    "\n",
    "## lets compute the accuracy b/n the actual and generated predictions\n",
    "accScore = accuracy_score(y_valid, y_valid_pred)\n",
    "\n",
    "## \n",
    "f1Score = f1_score(y_valid, y_valid_pred, average=\"macro\")\n",
    "\n",
    "##\n",
    "precisionScore = precision_score(y_valid, y_valid_pred, average=\"macro\")\n",
    "\n",
    "##\n",
    "recallScore = recall_score(y_valid, y_valid_pred, average=\"macro\")\n",
    "\n",
    "run.log(\"Validation Accuracy Score:\", accScore)\n",
    "run.log(\"Validation f1 Score:\", f1Score)\n",
    "run.log(\"Validation precision Score:\", precisionScore)\n",
    "run.log(\"Validation Recall Score:\", recallScore)\n",
    "#run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets generates the predictions for svm classifier\n",
    "y_valid_pred = rf.predict(X_valid)\n",
    "\n",
    "## lets compute the accuracy b/n the actual and generated predictions\n",
    "accScore = accuracy_score(y_valid, y_valid_pred)\n",
    "\n",
    "## \n",
    "f1Score = f1_score(y_valid, y_valid_pred, average=\"macro\")\n",
    "\n",
    "##\n",
    "precisionScore = precision_score(y_valid, y_valid_pred, average=\"macro\")\n",
    "\n",
    "##\n",
    "recallScore = recall_score(y_valid, y_valid_pred, average=\"macro\")\n",
    "\n",
    "run.log(\"Validation Accuracy Score:\", accScore)\n",
    "run.log(\"Validation f1 Score:\", f1Score)\n",
    "run.log(\"Validation precision Score:\", precisionScore)\n",
    "run.log(\"Validation Recall Score:\", recallScore)\n",
    "#run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(svc, initial_types=initial_type)\n",
    "\n",
    "## \n",
    "with open(\"outputs/svc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(rf, initial_types=initial_type)\n",
    "\n",
    "## \n",
    "with open(\"outputs/rf.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration Models And Production Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(model_path=\"outputs/svc.onnx\",\n",
    "                       model_name=\"Support-vector-classifier\", \n",
    "                       tags={'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'valid_data-accuracy': '0.9519'}, \n",
    "                       model_framework=\"pandas==0.23.4\",\n",
    "                       description=\"Support Vector Classifier for predicting weather at port of Turku\",\n",
    "                      workspace=workspace)\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(model_path=\"outputs/rf.onnx\",\n",
    "                       model_name=\"random-forest-classifier\", \n",
    "                       tags={'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'valid_data-accuracy': '0.9519'}, \n",
    "                       model_framework=\"pandas==0.23.4\",\n",
    "                       description=\"Random Forest Classifier for predicting weather at port of Turku\",\n",
    "                      workspace=workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registering Production Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./outputs/scaler.pkl\", \"wb\") as scaler_pkl:\n",
    "    pickle.dump(sc, scaler_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(model_path=\"outputs/scaler.pkl\",\n",
    "                       model_name=\"scaler\", \n",
    "                       tags={'dataset': dataset.name, 'version': dataset.version}, \n",
    "                       model_framework=\"pandas==0.23.4\",\n",
    "                       description=\"Scaler used for scaling incoming inference data\",\n",
    "                      workspace=workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "959b12ecb7ebf18c076d5166be666930742dfa4111a5e25fe4f7aee58d90cbc0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('ml_port_weather_prediction-zxRO_yOp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
